{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Autoregression\n",
    "Here we fit NeuralProphet to data with 5-minute resolution (daily temperatures at Yosemite). \n",
    "This is a continuation of the example notebook `autoregression_yosemite_temps`, focusing on sparsity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install git+https://github.com/ourownstory/neural_prophet.git # may take a while\n",
    "    #!pip install neuralprophet # much faster, but may not have the latest upgrades/bugfixes\n",
    "    data_location = \"https://raw.githubusercontent.com/ourownstory/neural_prophet/master/\"\n",
    "else:\n",
    "    data_location = \"../../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet , set_log_level, plot_plotly , plot_model_parameters_plotly\n",
    "set_log_level(\"ERROR\")\n",
    "df = pd.read_csv(data_location + \"example_data/yosemite_temps.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsifying the AR coefficients\n",
    "The autoregression component of NeuralProphet is defined as a AR-Net ([paper](https://arxiv.org/abs/1911.12436), [github](https://github.com/ourownstory/AR-Net)).\n",
    "Thus, we can set `ar_sparsity` to a number smaller one, if we like to induce sparsity in the AR coefficients. \n",
    "\n",
    "However, fitting a model with multiple components and regularizations can be harder to fit and you may need to take manual control over the training hyperparameters.\n",
    "\n",
    "\n",
    "We will start by setting a sparsity to 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = NeuralProphet(\n",
    "    n_lags=6*12,\n",
    "    n_forecasts=3*12,\n",
    "    changepoints_range=0.95,\n",
    "    n_changepoints=30,\n",
    "    weekly_seasonality=False,\n",
    "#     batch_size=64,\n",
    "#     epochs=100,    \n",
    "#     learning_rate=0.1,\n",
    "    ar_sparsity=0.5,\n",
    ")\n",
    "metrics = m.fit(df, freq='5min') # validate_each_epoch=True, plot_live_loss=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_parameters_plotly.plot_parameters(m,forecast_in_focus=m.highlight_forecast_step_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.highlight_nth_step_ahead_of_each_forecast(1)\n",
    "plot_model_parameters_plotly.plot_parameters(m,forecast_in_focus=m.highlight_forecast_step_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.highlight_nth_step_ahead_of_each_forecast(36)\n",
    "plot_model_parameters_plotly.plot_parameters(m,forecast_in_focus=m.highlight_forecast_step_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reducing the non-zero AR-coefficents\n",
    "By setting the ar_sparsity lower, we can further reduce the number of non-zero weights.\n",
    "Here we set it to 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = NeuralProphet(\n",
    "    n_lags=6*12,\n",
    "    n_forecasts=3*12,\n",
    "    changepoints_range=0.95,\n",
    "    n_changepoints=30,\n",
    "    weekly_seasonality=False,\n",
    "#     batch_size=64,\n",
    "#     epochs=100,    \n",
    "#     learning_rate=0.1,\n",
    "    ar_sparsity=0.1,\n",
    ")\n",
    "metrics = m.fit(df, freq='5min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_param = m.plot_parameters()\n",
    "plot_model_parameters_plotly.plot_parameters(m,forecast_in_focus=m.highlight_forecast_step_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.highlight_nth_step_ahead_of_each_forecast(1)\n",
    "plot_model_parameters_plotly.plot_parameters(m,forecast_in_focus=m.highlight_forecast_step_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.highlight_nth_step_ahead_of_each_forecast(36)\n",
    "plot_model_parameters_plotly.plot_parameters(m,forecast_in_focus=m.highlight_forecast_step_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme sparsity\n",
    "The lower we set `ar_sparsity`, the fewer non-zero weiths are fitted by the model. Here we set it to 1%, which should lead to a single non-zero lag.\n",
    "\n",
    "Note: Extreme values can lead to training instability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = NeuralProphet(\n",
    "    n_lags=6*12,\n",
    "    n_forecasts=3*12,\n",
    "    changepoints_range=0.95,\n",
    "    n_changepoints=30,\n",
    "    weekly_seasonality=False,\n",
    "#     batch_size=64,\n",
    "#     epochs=100,    \n",
    "#     learning_rate=0.1,\n",
    "    ar_sparsity=0.01,\n",
    ")\n",
    "metrics = m.fit(df, freq='5min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_param = m.plot_parameters()\n",
    "plot_model_parameters_plotly.plot_parameters(m,forecast_in_focus=m.highlight_forecast_step_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.highlight_nth_step_ahead_of_each_forecast(1)\n",
    "fig_param = m.plot_parameters()\n",
    "plot_model_parameters_plotly.plot_parameters(m,forecast_in_focus=m.highlight_forecast_step_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.highlight_nth_step_ahead_of_each_forecast(36)\n",
    "fig_param = m.plot_parameters()\n",
    "plot_model_parameters_plotly.plot_parameters(m,forecast_in_focus=m.highlight_forecast_step_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = m.make_future_dataframe(df, periods=365, n_historic_predictions=len(df))\n",
    "future.tail(3)\n",
    "forecast = m.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plotly.plot(m,forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nprophet",
   "language": "python",
   "name": "nprophet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
